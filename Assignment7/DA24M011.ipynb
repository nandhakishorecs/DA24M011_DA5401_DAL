{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"text-align: center\"> DA5401 Data Analytics Labarotary  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"text-align: center\">Assignment 7 - Submitted by: DA24M011 - Nandhakishore C S</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-aligh: justify;'> \n",
    "\t<b>Important:</b>\n",
    "</p>\n",
    "<p style='text-align: justify;'> Check the file output.txt for the verbose from gridsearch and the classification report for task 1. Check the file smote.txt for the verbose and classification for task 2. As the terminal output in a ipynb notebook was long and it affected exporting the notebook as a .pdf file, I saved the terminal outputs in separate file. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> (From Question) </p>\n",
    "<p style='text-aligh: justify;'> \n",
    "\tLet’s learn to deal with class-imbalance this time! We will consider the <a href = \"https://archive.ics.uci.edu/dataset/414/ida2016challenge\">IDA2016 Challengedataset</a> for our experimentation. The dataset is a binary classification y = {‘pos’, ‘neg’} problem with 170 features and 60,000 data points. The craziness here is that the class ratio is 1:59, that is, for every positive data point, there are 59 negative data points in the training data. The challenge dataset has a training file(aps_failure_training_set.csv) and a testing file (aps_failure_test_set.csv). We will consider only the training file for our experimentation\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 [20 Points]\n",
    "\n",
    "<p style='text-align: justify;'> (From Question) <p>\n",
    "\n",
    "<p style='text-align: justify;'> \n",
    "    Split the data file (aps_failure_training_set.csv) into train and test partitions. Build baseline classifiers {SVC, LogReg and DecisionTree} by cross-validating the best hyper-parameters of the respective models. For SVC, the hyperparametes are {kernel, kernel-params}; for LogReg {regularization choice L1/L2, regularization params}; and for DT {depth, leaf size}.Upon using GridSearchCV, the best parameters are to be found. Note that, GridSearchCV does 5-fold CV by default, which is sufficient for us. Once the parameters are fixed, you will learn the models on the train partition and report the performance metrics on the train and test partitions\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Importing Libraries <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling, visualisation and matrix operation \n",
    "import pandas as pd  \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# type: ignore\n",
    "import numpy as np \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# type: ignore\n",
    "import matplotlib.pyplot as plt\t\t\t\t\t\t\t\t\t\t\t\t\t\t# type: ignore\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\t\t\t\t\t\t# type: ignore\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\t\t\t\t\t# type: ignore\n",
    "\n",
    "# Machine learning algorithms - Support vector classifier, Logistic Rgeression and Decision Trees\n",
    "from sklearn.linear_model import LogisticRegression \t\t\t\t\t\t\t\t# type: ignore \n",
    "from sklearn.tree import DecisionTreeClassifier \t\t\t\t\t\t\t\t\t# type: ignore\n",
    "from sklearn.svm import SVC\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# type: ignore\n",
    "\n",
    "# Class imbalance learning \n",
    "from imblearn.over_sampling import SMOTE\t\t\t\t\t\t\t\t\t\t\t# type: ignore\n",
    "from imblearn.under_sampling import RandomUnderSampler\t\t\t\t\t\t\t\t# type: ignore\n",
    "from imblearn.pipeline import Pipeline\t\t\t\t\t\t\t\t\t\t\t\t# type: ignore\n",
    "\n",
    "from sklearn.utils import class_weight\t\t\t\t\t\t\t\t\t\t\t\t# type: ignore\n",
    "from sklearn.utils.class_weight import compute_sample_weight, compute_class_weight\t# type: ignore\n",
    "\n",
    "# Ensemble Learning \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\t\t# type: ignore\n",
    "\n",
    "# Classification Metrics\n",
    "from sklearn.metrics import f1_score, classification_report\t\t\t\t\t\t\t# type: ignore\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Importing Dataset <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = '/Users/nandhakishorecs/Documents/IITM/Jul_2024/DA5401/Assignments/Assignment7/to_uci/aps_failure_training_set.csv'\n",
    "df_raw = pd.read_csv(df_path, skiprows=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>76698</td>\n",
       "      <td>na</td>\n",
       "      <td>2130706438</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1240520</td>\n",
       "      <td>493384</td>\n",
       "      <td>721044</td>\n",
       "      <td>469792</td>\n",
       "      <td>339156</td>\n",
       "      <td>157956</td>\n",
       "      <td>73224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>33058</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>421400</td>\n",
       "      <td>178064</td>\n",
       "      <td>293306</td>\n",
       "      <td>245416</td>\n",
       "      <td>133654</td>\n",
       "      <td>81140</td>\n",
       "      <td>97576</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>41040</td>\n",
       "      <td>na</td>\n",
       "      <td>228</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>277378</td>\n",
       "      <td>159812</td>\n",
       "      <td>423992</td>\n",
       "      <td>409564</td>\n",
       "      <td>320746</td>\n",
       "      <td>158022</td>\n",
       "      <td>95128</td>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>46</td>\n",
       "      <td>58</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>60874</td>\n",
       "      <td>na</td>\n",
       "      <td>1368</td>\n",
       "      <td>458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>622012</td>\n",
       "      <td>229790</td>\n",
       "      <td>405298</td>\n",
       "      <td>347188</td>\n",
       "      <td>286954</td>\n",
       "      <td>311560</td>\n",
       "      <td>433954</td>\n",
       "      <td>1218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>neg</td>\n",
       "      <td>153002</td>\n",
       "      <td>na</td>\n",
       "      <td>664</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>998500</td>\n",
       "      <td>566884</td>\n",
       "      <td>1290398</td>\n",
       "      <td>1218244</td>\n",
       "      <td>1019768</td>\n",
       "      <td>717762</td>\n",
       "      <td>898642</td>\n",
       "      <td>28588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>neg</td>\n",
       "      <td>2286</td>\n",
       "      <td>na</td>\n",
       "      <td>2130706538</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10578</td>\n",
       "      <td>6760</td>\n",
       "      <td>21126</td>\n",
       "      <td>68424</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>neg</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>2130706432</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>792</td>\n",
       "      <td>386</td>\n",
       "      <td>452</td>\n",
       "      <td>144</td>\n",
       "      <td>146</td>\n",
       "      <td>2622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>neg</td>\n",
       "      <td>80292</td>\n",
       "      <td>na</td>\n",
       "      <td>2130706432</td>\n",
       "      <td>494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>699352</td>\n",
       "      <td>222654</td>\n",
       "      <td>347378</td>\n",
       "      <td>225724</td>\n",
       "      <td>194440</td>\n",
       "      <td>165070</td>\n",
       "      <td>802280</td>\n",
       "      <td>388422</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>neg</td>\n",
       "      <td>40222</td>\n",
       "      <td>na</td>\n",
       "      <td>698</td>\n",
       "      <td>628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>440066</td>\n",
       "      <td>183200</td>\n",
       "      <td>344546</td>\n",
       "      <td>254068</td>\n",
       "      <td>225148</td>\n",
       "      <td>158304</td>\n",
       "      <td>170384</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class  aa_000 ab_000      ac_000 ad_000 ae_000 af_000 ag_000 ag_001  \\\n",
       "0       neg   76698     na  2130706438    280      0      0      0      0   \n",
       "1       neg   33058     na           0     na      0      0      0      0   \n",
       "2       neg   41040     na         228    100      0      0      0      0   \n",
       "3       neg      12      0          70     66      0     10      0      0   \n",
       "4       neg   60874     na        1368    458      0      0      0      0   \n",
       "...     ...     ...    ...         ...    ...    ...    ...    ...    ...   \n",
       "59995   neg  153002     na         664    186      0      0      0      0   \n",
       "59996   neg    2286     na  2130706538    224      0      0      0      0   \n",
       "59997   neg     112      0  2130706432     18      0      0      0      0   \n",
       "59998   neg   80292     na  2130706432    494      0      0      0      0   \n",
       "59999   neg   40222     na         698    628      0      0      0      0   \n",
       "\n",
       "      ag_002  ...   ee_002  ee_003   ee_004   ee_005   ee_006  ee_007  ee_008  \\\n",
       "0          0  ...  1240520  493384   721044   469792   339156  157956   73224   \n",
       "1          0  ...   421400  178064   293306   245416   133654   81140   97576   \n",
       "2          0  ...   277378  159812   423992   409564   320746  158022   95128   \n",
       "3          0  ...      240      46       58       44       10       0       0   \n",
       "4          0  ...   622012  229790   405298   347188   286954  311560  433954   \n",
       "...      ...  ...      ...     ...      ...      ...      ...     ...     ...   \n",
       "59995      0  ...   998500  566884  1290398  1218244  1019768  717762  898642   \n",
       "59996      0  ...    10578    6760    21126    68424      136       0       0   \n",
       "59997      0  ...      792     386      452      144      146    2622       0   \n",
       "59998      0  ...   699352  222654   347378   225724   194440  165070  802280   \n",
       "59999      0  ...   440066  183200   344546   254068   225148  158304  170384   \n",
       "\n",
       "       ee_009 ef_000 eg_000  \n",
       "0           0      0      0  \n",
       "1        1500      0      0  \n",
       "2         514      0      0  \n",
       "3           0      4     32  \n",
       "4        1218      0      0  \n",
       "...       ...    ...    ...  \n",
       "59995   28588      0      0  \n",
       "59996       0      0      0  \n",
       "59997       0      0      0  \n",
       "59998  388422      0      0  \n",
       "59999     158      0      0  \n",
       "\n",
       "[60000 rows x 171 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> The dataset has 'na' as elements, which are basically numpy.nan values. <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Deep Copy of dataframes to remove 'na' values <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class', 'aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000', 'af_000',\n",
       "       'ag_000', 'ag_001', 'ag_002',\n",
       "       ...\n",
       "       'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008',\n",
       "       'ee_009', 'ef_000', 'eg_000'],\n",
       "      dtype='object', length=171)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_np = df_raw\n",
    "df = df_raw\n",
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class     object\n",
       "aa_000     int64\n",
       "ab_000    object\n",
       "ac_000    object\n",
       "ad_000    object\n",
       "           ...  \n",
       "ee_007    object\n",
       "ee_008    object\n",
       "ee_009    object\n",
       "ef_000    object\n",
       "eg_000    object\n",
       "Length: 171, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Also, the elements in the dataframe are not numbers, rather they are objects with non - float / integer values. we need to convert them into numbers <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['class'])\n",
    "df_np = df_np.drop(columns = ['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Converting dataframe into a numpy array to check for na values and replacing the 'na' values with the mean of the columns. <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76698</td>\n",
       "      <td>na</td>\n",
       "      <td>2130706438</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1240520</td>\n",
       "      <td>493384</td>\n",
       "      <td>721044</td>\n",
       "      <td>469792</td>\n",
       "      <td>339156</td>\n",
       "      <td>157956</td>\n",
       "      <td>73224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33058</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>421400</td>\n",
       "      <td>178064</td>\n",
       "      <td>293306</td>\n",
       "      <td>245416</td>\n",
       "      <td>133654</td>\n",
       "      <td>81140</td>\n",
       "      <td>97576</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41040</td>\n",
       "      <td>na</td>\n",
       "      <td>228</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>277378</td>\n",
       "      <td>159812</td>\n",
       "      <td>423992</td>\n",
       "      <td>409564</td>\n",
       "      <td>320746</td>\n",
       "      <td>158022</td>\n",
       "      <td>95128</td>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>46</td>\n",
       "      <td>58</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60874</td>\n",
       "      <td>na</td>\n",
       "      <td>1368</td>\n",
       "      <td>458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>622012</td>\n",
       "      <td>229790</td>\n",
       "      <td>405298</td>\n",
       "      <td>347188</td>\n",
       "      <td>286954</td>\n",
       "      <td>311560</td>\n",
       "      <td>433954</td>\n",
       "      <td>1218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>153002</td>\n",
       "      <td>na</td>\n",
       "      <td>664</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2564</td>\n",
       "      <td>...</td>\n",
       "      <td>998500</td>\n",
       "      <td>566884</td>\n",
       "      <td>1290398</td>\n",
       "      <td>1218244</td>\n",
       "      <td>1019768</td>\n",
       "      <td>717762</td>\n",
       "      <td>898642</td>\n",
       "      <td>28588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>2286</td>\n",
       "      <td>na</td>\n",
       "      <td>2130706538</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10578</td>\n",
       "      <td>6760</td>\n",
       "      <td>21126</td>\n",
       "      <td>68424</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>2130706432</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>792</td>\n",
       "      <td>386</td>\n",
       "      <td>452</td>\n",
       "      <td>144</td>\n",
       "      <td>146</td>\n",
       "      <td>2622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>80292</td>\n",
       "      <td>na</td>\n",
       "      <td>2130706432</td>\n",
       "      <td>494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>699352</td>\n",
       "      <td>222654</td>\n",
       "      <td>347378</td>\n",
       "      <td>225724</td>\n",
       "      <td>194440</td>\n",
       "      <td>165070</td>\n",
       "      <td>802280</td>\n",
       "      <td>388422</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>40222</td>\n",
       "      <td>na</td>\n",
       "      <td>698</td>\n",
       "      <td>628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>440066</td>\n",
       "      <td>183200</td>\n",
       "      <td>344546</td>\n",
       "      <td>254068</td>\n",
       "      <td>225148</td>\n",
       "      <td>158304</td>\n",
       "      <td>170384</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa_000 ab_000      ac_000 ad_000 ae_000 af_000 ag_000 ag_001 ag_002  \\\n",
       "0       76698     na  2130706438    280      0      0      0      0      0   \n",
       "1       33058     na           0     na      0      0      0      0      0   \n",
       "2       41040     na         228    100      0      0      0      0      0   \n",
       "3          12      0          70     66      0     10      0      0      0   \n",
       "4       60874     na        1368    458      0      0      0      0      0   \n",
       "...       ...    ...         ...    ...    ...    ...    ...    ...    ...   \n",
       "59995  153002     na         664    186      0      0      0      0      0   \n",
       "59996    2286     na  2130706538    224      0      0      0      0      0   \n",
       "59997     112      0  2130706432     18      0      0      0      0      0   \n",
       "59998   80292     na  2130706432    494      0      0      0      0      0   \n",
       "59999   40222     na         698    628      0      0      0      0      0   \n",
       "\n",
       "      ag_003  ...   ee_002  ee_003   ee_004   ee_005   ee_006  ee_007  ee_008  \\\n",
       "0          0  ...  1240520  493384   721044   469792   339156  157956   73224   \n",
       "1          0  ...   421400  178064   293306   245416   133654   81140   97576   \n",
       "2          0  ...   277378  159812   423992   409564   320746  158022   95128   \n",
       "3        318  ...      240      46       58       44       10       0       0   \n",
       "4          0  ...   622012  229790   405298   347188   286954  311560  433954   \n",
       "...      ...  ...      ...     ...      ...      ...      ...     ...     ...   \n",
       "59995   2564  ...   998500  566884  1290398  1218244  1019768  717762  898642   \n",
       "59996      0  ...    10578    6760    21126    68424      136       0       0   \n",
       "59997      0  ...      792     386      452      144      146    2622       0   \n",
       "59998      0  ...   699352  222654   347378   225724   194440  165070  802280   \n",
       "59999      0  ...   440066  183200   344546   254068   225148  158304  170384   \n",
       "\n",
       "       ee_009 ef_000 eg_000  \n",
       "0           0      0      0  \n",
       "1        1500      0      0  \n",
       "2         514      0      0  \n",
       "3           0      4     32  \n",
       "4        1218      0      0  \n",
       "...       ...    ...    ...  \n",
       "59995   28588      0      0  \n",
       "59996       0      0      0  \n",
       "59997       0      0      0  \n",
       "59998  388422      0      0  \n",
       "59999     158      0      0  \n",
       "\n",
       "[60000 rows x 170 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_np = np.array(df_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[76698, 'na', '2130706438', ..., '0', '0', '0'],\n",
       "       [33058, 'na', '0', ..., '1500', '0', '0'],\n",
       "       [41040, 'na', '228', ..., '514', '0', '0'],\n",
       "       ...,\n",
       "       [112, '0', '2130706432', ..., '0', '0', '0'],\n",
       "       [80292, 'na', '2130706432', ..., '388422', '0', '0'],\n",
       "       [40222, 'na', '698', ..., '158', '0', '0']], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, df_np.shape[0]):\n",
    "    for j in range(0, df_np.shape[1]): \n",
    "        if(df_np[i][j] == 'na'): \n",
    "            df_np[i][j] = np.nan\n",
    "        df_np[i][j] = float(df_np[i][j])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[76698.0, nan, 2130706438.0, ..., 0.0, 0.0, 0.0],\n",
       "       [33058.0, nan, 0.0, ..., 1500.0, 0.0, 0.0],\n",
       "       [41040.0, nan, 228.0, ..., 514.0, 0.0, 0.0],\n",
       "       ...,\n",
       "       [112.0, 0.0, 2130706432.0, ..., 0.0, 0.0, 0.0],\n",
       "       [80292.0, nan, 2130706432.0, ..., 388422.0, 0.0, 0.0],\n",
       "       [40222.0, nan, 698.0, ..., 158.0, 0.0, 0.0]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_means = np.nanmean(df_np, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[76698, 'na', '2130706438', ..., '0', '0', '0'],\n",
       "       [33058, 'na', '0', ..., '1500', '0', '0'],\n",
       "       [41040, 'na', '228', ..., '514', '0', '0'],\n",
       "       ...,\n",
       "       [112, '0', '2130706432', ..., '0', '0', '0'],\n",
       "       [80292, 'na', '2130706432', ..., '388422', '0', '0'],\n",
       "       [40222, 'na', '698', ..., '158', '0', '0']], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = np.array(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, df.shape[0]): \n",
    "    for j in range(0, df.shape[1]): \n",
    "        if(df[i][j] == 'na'):\n",
    "            df[i][j] = col_means[j]\n",
    "        df[i][j] = float(df[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of classes:\t 60000\n"
     ]
    }
   ],
   "source": [
    "class_column = df_raw['class']\n",
    "print('len of classes:\\t', len(class_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of the header 171\n"
     ]
    }
   ],
   "source": [
    "print('len of the header', len(df_raw.columns ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['neg', 76698.0, 0.7131885012069343, ..., 0.0, 0.0, 0.0],\n",
       "       ['neg', 33058.0, 0.7131885012069343, ..., 1500.0, 0.0, 0.0],\n",
       "       ['neg', 41040.0, 0.7131885012069343, ..., 514.0, 0.0, 0.0],\n",
       "       ...,\n",
       "       ['neg', 112.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "       ['neg', 80292.0, 0.7131885012069343, ..., 388422.0, 0.0, 0.0],\n",
       "       ['neg', 40222.0, 0.7131885012069343, ..., 158.0, 0.0, 0.0]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = np.c_[class_column, df]\n",
    "#df = np.r_[df_raw.columns, df]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class', 'aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000',\n",
       "       'af_000', 'ag_000', 'ag_001', 'ag_002', 'ag_003', 'ag_004',\n",
       "       'ag_005', 'ag_006', 'ag_007', 'ag_008', 'ag_009', 'ah_000',\n",
       "       'ai_000', 'aj_000', 'ak_000', 'al_000', 'am_0', 'an_000', 'ao_000',\n",
       "       'ap_000', 'aq_000', 'ar_000', 'as_000', 'at_000', 'au_000',\n",
       "       'av_000', 'ax_000', 'ay_000', 'ay_001', 'ay_002', 'ay_003',\n",
       "       'ay_004', 'ay_005', 'ay_006', 'ay_007', 'ay_008', 'ay_009',\n",
       "       'az_000', 'az_001', 'az_002', 'az_003', 'az_004', 'az_005',\n",
       "       'az_006', 'az_007', 'az_008', 'az_009', 'ba_000', 'ba_001',\n",
       "       'ba_002', 'ba_003', 'ba_004', 'ba_005', 'ba_006', 'ba_007',\n",
       "       'ba_008', 'ba_009', 'bb_000', 'bc_000', 'bd_000', 'be_000',\n",
       "       'bf_000', 'bg_000', 'bh_000', 'bi_000', 'bj_000', 'bk_000',\n",
       "       'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000',\n",
       "       'br_000', 'bs_000', 'bt_000', 'bu_000', 'bv_000', 'bx_000',\n",
       "       'by_000', 'bz_000', 'ca_000', 'cb_000', 'cc_000', 'cd_000',\n",
       "       'ce_000', 'cf_000', 'cg_000', 'ch_000', 'ci_000', 'cj_000',\n",
       "       'ck_000', 'cl_000', 'cm_000', 'cn_000', 'cn_001', 'cn_002',\n",
       "       'cn_003', 'cn_004', 'cn_005', 'cn_006', 'cn_007', 'cn_008',\n",
       "       'cn_009', 'co_000', 'cp_000', 'cq_000', 'cr_000', 'cs_000',\n",
       "       'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005', 'cs_006',\n",
       "       'cs_007', 'cs_008', 'cs_009', 'ct_000', 'cu_000', 'cv_000',\n",
       "       'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000',\n",
       "       'dd_000', 'de_000', 'df_000', 'dg_000', 'dh_000', 'di_000',\n",
       "       'dj_000', 'dk_000', 'dl_000', 'dm_000', 'dn_000', 'do_000',\n",
       "       'dp_000', 'dq_000', 'dr_000', 'ds_000', 'dt_000', 'du_000',\n",
       "       'dv_000', 'dx_000', 'dy_000', 'dz_000', 'ea_000', 'eb_000',\n",
       "       'ec_00', 'ed_000', 'ee_000', 'ee_001', 'ee_002', 'ee_003',\n",
       "       'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009',\n",
       "       'ef_000', 'eg_000'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = np.array(df_raw.columns)\n",
    "header "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>76698.0</td>\n",
       "      <td>0.713189</td>\n",
       "      <td>2130706438.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1240520.0</td>\n",
       "      <td>493384.0</td>\n",
       "      <td>721044.0</td>\n",
       "      <td>469792.0</td>\n",
       "      <td>339156.0</td>\n",
       "      <td>157956.0</td>\n",
       "      <td>73224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>33058.0</td>\n",
       "      <td>0.713189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190620.639314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>421400.0</td>\n",
       "      <td>178064.0</td>\n",
       "      <td>293306.0</td>\n",
       "      <td>245416.0</td>\n",
       "      <td>133654.0</td>\n",
       "      <td>81140.0</td>\n",
       "      <td>97576.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>41040.0</td>\n",
       "      <td>0.713189</td>\n",
       "      <td>228.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>277378.0</td>\n",
       "      <td>159812.0</td>\n",
       "      <td>423992.0</td>\n",
       "      <td>409564.0</td>\n",
       "      <td>320746.0</td>\n",
       "      <td>158022.0</td>\n",
       "      <td>95128.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>60874.0</td>\n",
       "      <td>0.713189</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>622012.0</td>\n",
       "      <td>229790.0</td>\n",
       "      <td>405298.0</td>\n",
       "      <td>347188.0</td>\n",
       "      <td>286954.0</td>\n",
       "      <td>311560.0</td>\n",
       "      <td>433954.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>neg</td>\n",
       "      <td>153002.0</td>\n",
       "      <td>0.713189</td>\n",
       "      <td>664.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>998500.0</td>\n",
       "      <td>566884.0</td>\n",
       "      <td>1290398.0</td>\n",
       "      <td>1218244.0</td>\n",
       "      <td>1019768.0</td>\n",
       "      <td>717762.0</td>\n",
       "      <td>898642.0</td>\n",
       "      <td>28588.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>neg</td>\n",
       "      <td>2286.0</td>\n",
       "      <td>0.713189</td>\n",
       "      <td>2130706538.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10578.0</td>\n",
       "      <td>6760.0</td>\n",
       "      <td>21126.0</td>\n",
       "      <td>68424.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>neg</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2130706432.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>792.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>2622.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>neg</td>\n",
       "      <td>80292.0</td>\n",
       "      <td>0.713189</td>\n",
       "      <td>2130706432.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>699352.0</td>\n",
       "      <td>222654.0</td>\n",
       "      <td>347378.0</td>\n",
       "      <td>225724.0</td>\n",
       "      <td>194440.0</td>\n",
       "      <td>165070.0</td>\n",
       "      <td>802280.0</td>\n",
       "      <td>388422.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>neg</td>\n",
       "      <td>40222.0</td>\n",
       "      <td>0.713189</td>\n",
       "      <td>698.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>440066.0</td>\n",
       "      <td>183200.0</td>\n",
       "      <td>344546.0</td>\n",
       "      <td>254068.0</td>\n",
       "      <td>225148.0</td>\n",
       "      <td>158304.0</td>\n",
       "      <td>170384.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class    aa_000    ab_000        ac_000         ad_000 ae_000 af_000  \\\n",
       "0       neg   76698.0  0.713189  2130706438.0          280.0    0.0    0.0   \n",
       "1       neg   33058.0  0.713189           0.0  190620.639314    0.0    0.0   \n",
       "2       neg   41040.0  0.713189         228.0          100.0    0.0    0.0   \n",
       "3       neg      12.0       0.0          70.0           66.0    0.0   10.0   \n",
       "4       neg   60874.0  0.713189        1368.0          458.0    0.0    0.0   \n",
       "...     ...       ...       ...           ...            ...    ...    ...   \n",
       "59995   neg  153002.0  0.713189         664.0          186.0    0.0    0.0   \n",
       "59996   neg    2286.0  0.713189  2130706538.0          224.0    0.0    0.0   \n",
       "59997   neg     112.0       0.0  2130706432.0           18.0    0.0    0.0   \n",
       "59998   neg   80292.0  0.713189  2130706432.0          494.0    0.0    0.0   \n",
       "59999   neg   40222.0  0.713189         698.0          628.0    0.0    0.0   \n",
       "\n",
       "      ag_000 ag_001 ag_002  ...     ee_002    ee_003     ee_004     ee_005  \\\n",
       "0        0.0    0.0    0.0  ...  1240520.0  493384.0   721044.0   469792.0   \n",
       "1        0.0    0.0    0.0  ...   421400.0  178064.0   293306.0   245416.0   \n",
       "2        0.0    0.0    0.0  ...   277378.0  159812.0   423992.0   409564.0   \n",
       "3        0.0    0.0    0.0  ...      240.0      46.0       58.0       44.0   \n",
       "4        0.0    0.0    0.0  ...   622012.0  229790.0   405298.0   347188.0   \n",
       "...      ...    ...    ...  ...        ...       ...        ...        ...   \n",
       "59995    0.0    0.0    0.0  ...   998500.0  566884.0  1290398.0  1218244.0   \n",
       "59996    0.0    0.0    0.0  ...    10578.0    6760.0    21126.0    68424.0   \n",
       "59997    0.0    0.0    0.0  ...      792.0     386.0      452.0      144.0   \n",
       "59998    0.0    0.0    0.0  ...   699352.0  222654.0   347378.0   225724.0   \n",
       "59999    0.0    0.0    0.0  ...   440066.0  183200.0   344546.0   254068.0   \n",
       "\n",
       "          ee_006    ee_007    ee_008    ee_009 ef_000 eg_000  \n",
       "0       339156.0  157956.0   73224.0       0.0    0.0    0.0  \n",
       "1       133654.0   81140.0   97576.0    1500.0    0.0    0.0  \n",
       "2       320746.0  158022.0   95128.0     514.0    0.0    0.0  \n",
       "3           10.0       0.0       0.0       0.0    4.0   32.0  \n",
       "4       286954.0  311560.0  433954.0    1218.0    0.0    0.0  \n",
       "...          ...       ...       ...       ...    ...    ...  \n",
       "59995  1019768.0  717762.0  898642.0   28588.0    0.0    0.0  \n",
       "59996      136.0       0.0       0.0       0.0    0.0    0.0  \n",
       "59997      146.0    2622.0       0.0       0.0    0.0    0.0  \n",
       "59998   194440.0  165070.0  802280.0  388422.0    0.0    0.0  \n",
       "59999   225148.0  158304.0  170384.0     158.0    0.0    0.0  \n",
       "\n",
       "[60000 rows x 171 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df.columns = df_raw.columns \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> The cells with 'na' values are converted into floating point elements and the header is added back for ease of handling data<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>22095.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2062.0</td>\n",
       "      <td>1887.000000</td>\n",
       "      <td>334.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>2423.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34489.0</td>\n",
       "      <td>31712.0</td>\n",
       "      <td>35189.0</td>\n",
       "      <td>36289.0</td>\n",
       "      <td>31796.0</td>\n",
       "      <td>30470.0</td>\n",
       "      <td>24214.0</td>\n",
       "      <td>9725.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>neg</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.713189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190620.639314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>59000</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>46329.000000</td>\n",
       "      <td>8752.0</td>\n",
       "      <td>14861.000000</td>\n",
       "      <td>55543.0</td>\n",
       "      <td>55476.0</td>\n",
       "      <td>59133.0</td>\n",
       "      <td>58587.0</td>\n",
       "      <td>56181.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>1797.0</td>\n",
       "      <td>2814.0</td>\n",
       "      <td>4458.0</td>\n",
       "      <td>7898.0</td>\n",
       "      <td>17280.0</td>\n",
       "      <td>31863.0</td>\n",
       "      <td>57021.0</td>\n",
       "      <td>56794.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        class   aa_000        ab_000   ac_000         ad_000   ae_000  \\\n",
       "count   60000  60000.0  60000.000000  60000.0   60000.000000  60000.0   \n",
       "unique      2  22095.0     30.000000   2062.0    1887.000000    334.0   \n",
       "top       neg      8.0      0.713189      0.0  190620.639314      0.0   \n",
       "freq    59000   1023.0  46329.000000   8752.0   14861.000000  55543.0   \n",
       "\n",
       "         af_000   ag_000   ag_001   ag_002  ...   ee_002   ee_003   ee_004  \\\n",
       "count   60000.0  60000.0  60000.0  60000.0  ...  60000.0  60000.0  60000.0   \n",
       "unique    419.0    155.0    618.0   2423.0  ...  34489.0  31712.0  35189.0   \n",
       "top         0.0      0.0      0.0      0.0  ...      0.0      0.0      0.0   \n",
       "freq    55476.0  59133.0  58587.0  56181.0  ...   1364.0   1557.0   1797.0   \n",
       "\n",
       "         ee_005   ee_006   ee_007   ee_008   ee_009   ef_000   eg_000  \n",
       "count   60000.0  60000.0  60000.0  60000.0  60000.0  60000.0  60000.0  \n",
       "unique  36289.0  31796.0  30470.0  24214.0   9725.0     29.0     50.0  \n",
       "top         0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "freq     2814.0   4458.0   7898.0  17280.0  31863.0  57021.0  56794.0  \n",
       "\n",
       "[4 rows x 171 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class     0\n",
       "aa_000    0\n",
       "ab_000    0\n",
       "ac_000    0\n",
       "ad_000    0\n",
       "         ..\n",
       "ee_007    0\n",
       "ee_008    0\n",
       "ee_009    0\n",
       "ef_000    0\n",
       "eg_000    0\n",
       "Length: 171, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> No null / nan values after data cleaning<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(columns = ['class']))\n",
    "y = np.array(df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Extracting features and classes from dataset for classification <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> From the histogtram we can see that, there is skewness and the dataset is highly imbalanced with respect to classes (as from question)!<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Also, we are lebel encoding the data for the ease of doing classification <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size = 0.3, shuffle=True, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Splitting the data into train test datasets <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = LabelEncoder().fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "dt_parameter_grid = { \n",
    "\t'max_depth' : [1, 10, 50, None],\n",
    "\t'max_leaf_nodes' : [2, 64, 128], \n",
    "\t'min_samples_leaf' : [8, 16, 32, 64], \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = dt_clf, \n",
    "\tparam_grid = dt_parameter_grid, \n",
    "    cv = 5, \n",
    "\tn_jobs = -1,  \n",
    "\tverbose = 3,\n",
    "\tscoring = 'f1_macro'\n",
    ")\n",
    "\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "best_tree_clf = grid_search.best_estimator_\n",
    "print(best_tree_clf)\n",
    "best_params_dt = grid_search.best_params_\n",
    "pred_y = best_tree_clf.predict(test_X)\n",
    "print(pred_y)\n",
    "dt_test_f1 = f1_score(test_y, pred_y)\n",
    "print(dt_test_f1)\n",
    "\n",
    "dt_best = DecisionTreeClassifier(**best_params_dt).fit(train_X, train_y)\n",
    "\n",
    "print(\"Decision Tree Performance on Train Set:\")\n",
    "print(classification_report(train_y, dt_best.predict(train_X), target_names=['Negative', 'Positive']))\n",
    "\n",
    "print(\"Decision Tree Performance on Test Set:\")\n",
    "print(classification_report(test_y, dt_best.predict(test_X), target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_XX = StandardScaler().fit_transform(train_X)\n",
    "\n",
    "logreg_clf =  LogisticRegression(max_iter = 1e+6)\n",
    "\n",
    "logreg_parameter_grid = {\n",
    "\t'C': [1000, 100, 10, 1],\n",
    "\t'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = logreg_clf, \n",
    "\tparam_grid = logreg_parameter_grid, \n",
    "    cv = 5, \n",
    "\tn_jobs = -1,  \n",
    "\tverbose = 3,\n",
    "\tscoring = 'f1_macro'\n",
    ")\n",
    "\n",
    "grid_search.fit(train_XX, train_y)\n",
    "\n",
    "test_XX = StandardScaler().fit_transform(test_X)\n",
    "\n",
    "best_logreg_clf = grid_search.best_estimator_\n",
    "best_params_logreg = grid_search.best_params_\n",
    "print(best_logreg_clf)\n",
    "\n",
    "pred_y = best_logreg_clf.predict(test_XX)\n",
    "logreg_test_f1 = f1_score(test_y, pred_y)\n",
    "print(logreg_test_f1)\n",
    "\n",
    "logreg_best = LogisticRegression(**best_params_logreg).fit(train_X, train_y)\n",
    "\n",
    "print(\"Logistic Regression Performance on Train Set:\")\n",
    "print(classification_report(train_y, logreg_best.predict(train_XX), target_names=['Negative', 'Positive']))\n",
    "\n",
    "print(\"Logistic Regression Performance on Test Set:\")\n",
    "print(classification_report(test_y, logreg_best.predict(test_XX), target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC()\n",
    "\n",
    "svm_parameter_grid = {\n",
    "    'gamma': [0, 1, 10],\n",
    "    'kernel': ['rbf', 'poly']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = svm_clf, \n",
    "\tparam_grid = svm_parameter_grid, \n",
    "    cv = 5, \n",
    "\tn_jobs = -1,  \n",
    "\tverbose = 3,\n",
    "\tscoring = 'f1_macro'\n",
    ")\n",
    "\n",
    "grid_search.fit(train_X, train_y)\n",
    "# %%\n",
    "best_svm_clf = grid_search.best_estimator_\n",
    "print(best_svm_clf)\n",
    "\n",
    "best_params_svc = grid_search.best_params_\n",
    "pred_y = best_svm_clf.predict(test_X)\n",
    "svm_test_f1 = f1_score(test_y, pred_y)\n",
    "print(svm_test_f1)\n",
    "\n",
    "svc_best = SVC(**best_params_svc).fit(train_X, train_y)\n",
    "print(\"SVC Performance on Train Set:\")\n",
    "print(classification_report(train_y, svc_best.predict(train_X), target_names=['Negative', 'Positive']))\n",
    "\n",
    "print(\"SVC Performance on Test Set:\")\n",
    "print(classification_report(test_y, svc_best.predict(test_X), target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Please refer <b>'output.txt'</b> for the output of above cells with their respective f1 score(s) and classification report(s) <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 [30 Points]\n",
    "\n",
    "<p style='text-align: justify;'> (From Question) <p>\n",
    "\n",
    "<p style='text-align: justify;'> \n",
    "    Now, we want to address the class imbalance via multiple approaches. You are expected to apply the following in all the three families of classifiers.\n",
    "</p>\n",
    "\n",
    "<ol>\n",
    "\t<li type='a'> Consider undersampling the majority class and/or oversampling the minority class.</li>\n",
    "\t<li type='a'> Consider using class_weight which is inversely proportional to the class population.</li>\n",
    "\t<li type='a'> Consider using sample_weights, where you may assign a penalty for misclassifying every data point depending on the class it falls in.</li>\n",
    "\t<li type='a'> Consider any other creative ideas to address the class imbalance.</li>\n",
    "</ol>\n",
    "\n",
    "<p style='text-align: justify;'> The goal here is the classification performance metric (macro average F_1) of the hacked classifiers should be better than the baseline classifiers <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Please refer <b>'smote.txt'</b> for the output of above cells with their respective f1 score(s) and classification report(s) <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> a. classification after undersampling the majority class / oversampling the minoruty class <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling the minority class\n",
    "oversample = SMOTE()\n",
    "X_train_oversampled, y_train_oversampled = oversample.fit_resample(train_X, train_y)\n",
    "X_test_oversampled, y_test_oversampled = oversample.fit_resample(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nFit on oversampled data: \\n')\n",
    "\n",
    "sv = SVC().fit(X_train_oversampled, y_train_oversampled)\n",
    "print(\"SVM Performance on Test Set:\")\n",
    "print(classification_report(y_test_oversampled, sv.predict(X_test_oversampled), target_names=['Negative', 'Positive']))\n",
    "print(\"SVM Performance on Train Set:\")\n",
    "print(classification_report(y_train_oversampled, sv.predict(X_train_oversampled), target_names=['Negative', 'Positive']))\n",
    "\n",
    "lg = LogisticRegression(max_iter = 1000000).fit(X_train_oversampled, y_train_oversampled)\n",
    "print(\"Logistic Regression Performance on Test Set:\")\n",
    "print(classification_report(y_test_oversampled, lg.predict(X_test_oversampled), target_names=['Negative', 'Positive']))\n",
    "print(\"Logistic Regression Performance on Train Set:\")\n",
    "print(classification_report(y_train_oversampled, lg.predict(X_train_oversampled), target_names=['Negative', 'Positive']))\n",
    "\n",
    "dt = DecisionTreeClassifier().fit(X_train_oversampled, y_train_oversampled)\n",
    "print(\"Decision Tree Performance on Test Set:\")\n",
    "print(classification_report(y_test_oversampled, dt.predict(X_test_oversampled), target_names=['Negative', 'Positive']))\n",
    "print(\"Decision Tree Performance on Train Set:\")\n",
    "print(classification_report(y_train_oversampled, dt.predict(X_train_oversampled), target_names=['Negative', 'Positive']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling the majority class\n",
    "undersample = RandomUnderSampler()\n",
    "X_train_undersampled, y_train_undersampled = undersample.fit_resample(train_X, train_y)\n",
    "X_test_undersampled, y_test_undersampled = undersample.fit_resample(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = SVC().fit(X_train_undersampled, y_train_undersampled)\n",
    "print(\"SVM Performance on Test Set:\")\n",
    "print(classification_report(y_test_undersampled, sv.predict(X_test_undersampled), target_names=['Negative', 'Positive']))\n",
    "print(\"SVM Performance on Train Set:\")\n",
    "print(classification_report(y_train_undersampled, sv.predict(X_train_undersampled), target_names=['Negative', 'Positive']))\n",
    "\n",
    "lg = LogisticRegression(max_iter = 1000000).fit(X_train_undersampled, y_train_undersampled)\n",
    "print(\"Logistic Regression Performance on Test Set:\")\n",
    "print(classification_report(y_test_undersampled, lg.predict(X_test_undersampled), target_names=['Negative', 'Positive']))\n",
    "print(\"Logistic Regression Performance on Train Set:\")\n",
    "print(classification_report(y_train_undersampled, lg.predict(X_train_undersampled), target_names=['Negative', 'Positive']))\n",
    "\n",
    "dt = DecisionTreeClassifier().fit(X_train_undersampled, y_train_undersampled)\n",
    "print(\"Decision Tree Performance on Test Set:\")\n",
    "print(classification_report(y_test_undersampled, dt.predict(X_test_undersampled), target_names=['Negative', 'Positive']))\n",
    "print(\"Decision Tree Performance on Train Set:\")\n",
    "print(classification_report(y_train_undersampled, dt.predict(X_train_undersampled), target_names=['Negative', 'Positive']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> b. classification using class weight argument in the classifiers <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting class weights inversely proportional to class frequencies\n",
    "svc_weighted = SVC(class_weight='balanced')\n",
    "logreg_weighted = LogisticRegression(class_weight='balanced', solver='liblinear')\n",
    "dt_weighted = DecisionTreeClassifier(class_weight='balanced')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> c. classification using sample weights <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign sample weights\n",
    "class_weights = dict(zip([0, 1], compute_class_weight('balanced', classes=[1,0],  y=train_y)))\n",
    "sample_weights =  compute_sample_weight(class_weight='balanced', y = train_y )  #train_y.map(class_weights)\n",
    "\n",
    "# Fitting models with sample weights\n",
    "svc_sample_weights = SVC().fit(train_X, train_y, sample_weight=sample_weights)\n",
    "logreg_sample_weights = LogisticRegression(solver='liblinear').fit(train_X, train_y, sample_weight=sample_weights)\n",
    "dt_sample_weights = DecisionTreeClassifier().fit(train_X, train_y, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> d. usign ensemble methods to do classification<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "rf.fit(train_X, train_y)\n",
    "gb.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> Results of classification after doing hacks<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weighted SVC Performance on Test Set:\")\n",
    "print(classification_report(test_y, svc_weighted.predict(test_X), target_names=['Negative', 'Positive']))\n",
    "\n",
    "print(\"Weighted Logistic Regression Performance on Test Set:\")\n",
    "print(classification_report(test_y, logreg_weighted.predict(test_X), target_names=['Negative', 'Positive']))\n",
    "\n",
    "print(\"Weighted Decision Tree Performance on Test Set:\")\n",
    "print(classification_report(test_y, dt_weighted.predict(test_X), target_names=['Negative', 'Positive']))\n",
    "\n",
    "print(\"Random Forest Performance on Test Set:\")\n",
    "print(classification_report(test_y, rf.predict(test_X), target_names=['Negative', 'Positive']))\n",
    "\n",
    "print(\"Gradient Boosting Performance on Test Set:\")\n",
    "print(classification_report(test_y, gb.predict(test_X), target_names=['Negative', 'Positive']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style='text-aligh: justify;'> <b>Conclusion:</b> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> When classification is done witth class imbalance, the F1 score for classification for class 'neg' is very close to 1 and for class 'pos', the value is less than 0.7 and for svm it is to null. This is due to the fact that, the population of classes with 'pos' labels is very skewed to an extent such that, the model takes it up as noise!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> When classification is done witth class oversampling / undersampling, the F1 score for classification for class 'neg' and class 'pos', are similar nearly stable at 0.9. But Oversampling / Undersampling might not be feasible because not all times a data point can be estimated into a probability distribution for sampling. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> When classification is done with class weights or sample weights (with penalty), the model(s) perform well and the f1 score is 0.99 for all the three models. The best result recorded is decision trees with f1 for negative class as .99 and .60 for positive class</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> From the accuracy score during the hyper parameter tuning phase, we can see that, all three classifiers (logistic regression, svm and decision trees) have accuracies not more than 60%. Thus we can use different classifiers as an ensemble and random forest and gradientboosting are built and the F1 score is best for random forest at 0.91 for negative class and 0.68 for negative class!</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
