{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"text-align: center\"> DA5401 Data Analytics Labarotary  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"text-align: center\">Assignment 6 - Submitted by: DA24M011 - Nandhakishore C S</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 [40 Points]\n",
    "\n",
    "<p style='text-align: justify;'> \n",
    "    Given the dataset (Amazon's MASSIVE dataset) - has data from 51 Languages in the latest version. For the given question, we are downloading the 27 files corresponding to languages which use the roman / latin script. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "    Importing Libraries \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \t\t\t\t\t\t\t# type: ignore \n",
    "from datasets import load_dataset\t\t\t# type: ignore \n",
    "from unidecode import unidecode \t\t\t# type: ignore\n",
    "\n",
    "import unicodedata\n",
    "from sklearn.naive_bayes import MultinomialNB\t# type: ignore \n",
    "from sklearn.preprocessing import LabelEncoder  # type: ignore \n",
    "from sklearn.pipeline import Pipeline\t\t\t# type: ignore \n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score # type: ignore \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer # type: ignore \n",
    "import pandas as pd\t\t\t\t\t\t\t\t# type: ignore "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tDefining the languages which use Latin Script and downloading the corresponsing files from the main dataset. \n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the locales we are interested in (i.e.) the languages which use Latin Script \n",
    "locales = [\n",
    "    'af-ZA', 'da-DK', 'de-DE', 'en-US', 'es-ES', 'fr-FR', 'fi-FI', 'hu-HU', 'is-IS', 'it-IT',\n",
    "    'jv-ID', 'lv-LV', 'ms-MY', 'nb-NO', 'nl-NL', 'pl-PL', 'pt-PT', 'ro-RO', 'ru-RU', 'sl-SL',\n",
    "    'sv-SE', 'sq-AL', 'sw-KE', 'tl-PH', 'tr-TR', 'vi-VN', 'cy-GB'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset - using Huggingface load dataset module / function \n",
    "df_raw = load_dataset(\"AmazonScience/massive\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'locale', 'partition', 'scenario', 'intent', 'utt', 'annot_utt', 'worker_id', 'slot_method', 'judgments'],\n",
       "        num_rows: 587214\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'locale', 'partition', 'scenario', 'intent', 'utt', 'annot_utt', 'worker_id', 'slot_method', 'judgments'],\n",
       "        num_rows: 103683\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'locale', 'partition', 'scenario', 'intent', 'utt', 'annot_utt', 'worker_id', 'slot_method', 'judgments'],\n",
       "        num_rows: 151674\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading and storing datafiles for 27 languages \n",
    "\n",
    "output_dir = 'language_files'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Extract utterances for each locale\n",
    "for locale in locales:\n",
    "    file_path = os.path.join(output_dir, f'{locale}.txt')\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        for partition in ['train', 'validation', 'test']:\n",
    "                for example in df_raw[partition]:\n",
    "                        if example['locale'] == locale:\n",
    "                                utt = example['utt']\n",
    "                                f.write(utt + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tThe dataset is split into three parttions: \n",
    "<p>\n",
    "\n",
    "1. Train \n",
    "2. Validation \n",
    "3. Test \n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "\tFrom the training partition, we get the 'utt' column as the input features (the sentences with / without) accents and the corresponsing country name in the 'locale' column as the label. \n",
    "\tInstead of using the tokens from the dataset, Tokens are generated using CountVectoriser from sklearn's feature extraction module.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tUsing '.filter' function to get the data corresponding to the country names\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'locale', 'partition', 'scenario', 'intent', 'utt', 'annot_utt', 'worker_id', 'slot_method', 'judgments'],\n",
       "        num_rows: 310878\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'locale', 'partition', 'scenario', 'intent', 'utt', 'annot_utt', 'worker_id', 'slot_method', 'judgments'],\n",
       "        num_rows: 54891\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'locale', 'partition', 'scenario', 'intent', 'utt', 'annot_utt', 'worker_id', 'slot_method', 'judgments'],\n",
       "        num_rows: 80298\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df_raw.filter(lambda x: x['locale'] in locales)\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tBuilding Multinomial Naive Bayes Model - without removing accents\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No accent removal \n",
    "df1_train = df_filtered['train']\n",
    "df1_val = df_filtered['validation']\n",
    "df1_test = df_filtered['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectoriser&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectoriser&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectoriser', CountVectorizer()),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectoriser', CountVectorizer()), \n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline.fit(df1_train['utt'], df1_train['locale'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tModel's perfomance metrics for Train Partition\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       af-ZA       0.98      0.98      0.98     11514\n",
      "       cy-GB       1.00      1.00      1.00     11514\n",
      "       da-DK       0.97      0.97      0.97     11514\n",
      "       de-DE       1.00      0.99      0.99     11514\n",
      "       en-US       0.96      0.99      0.98     11514\n",
      "       es-ES       0.99      0.99      0.99     11514\n",
      "       fi-FI       1.00      0.99      0.99     11514\n",
      "       fr-FR       0.99      0.99      0.99     11514\n",
      "       hu-HU       1.00      0.99      1.00     11514\n",
      "       is-IS       1.00      1.00      1.00     11514\n",
      "       it-IT       0.99      0.99      0.99     11514\n",
      "       jv-ID       0.99      0.99      0.99     11514\n",
      "       lv-LV       1.00      1.00      1.00     11514\n",
      "       ms-MY       0.99      0.99      0.99     11514\n",
      "       nb-NO       0.97      0.96      0.97     11514\n",
      "       nl-NL       0.99      0.98      0.98     11514\n",
      "       pl-PL       0.99      0.99      0.99     11514\n",
      "       pt-PT       0.99      0.99      0.99     11514\n",
      "       ro-RO       1.00      0.99      0.99     11514\n",
      "       ru-RU       1.00      1.00      1.00     11514\n",
      "       sl-SL       1.00      0.99      1.00     11514\n",
      "       sq-AL       1.00      0.99      1.00     11514\n",
      "       sv-SE       0.99      0.99      0.99     11514\n",
      "       sw-KE       1.00      1.00      1.00     11514\n",
      "       tl-PH       1.00      1.00      1.00     11514\n",
      "       tr-TR       1.00      0.99      1.00     11514\n",
      "       vi-VN       1.00      1.00      1.00     11514\n",
      "\n",
      "    accuracy                           0.99    310878\n",
      "   macro avg       0.99      0.99      0.99    310878\n",
      "weighted avg       0.99      0.99      0.99    310878\n",
      "\n",
      "Training Accuracy: 0.9909160506693945\n"
     ]
    }
   ],
   "source": [
    "train_predictions = pipeline.predict(df1_train['utt'])\n",
    "print(\"Training Data Performance:\")\n",
    "print(classification_report(df1_train['locale'], train_predictions))\n",
    "print(\"Training Accuracy:\", accuracy_score(df1_train['locale'], train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tModel's perfomance metrics for Validation Partition\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       af-ZA       0.91      0.98      0.94      2033\n",
      "       cy-GB       1.00      0.99      0.99      2033\n",
      "       da-DK       0.94      0.96      0.95      2033\n",
      "       de-DE       1.00      0.98      0.99      2033\n",
      "       en-US       0.96      0.99      0.98      2033\n",
      "       es-ES       0.98      0.98      0.98      2033\n",
      "       fi-FI       1.00      0.98      0.99      2033\n",
      "       fr-FR       0.99      0.99      0.99      2033\n",
      "       hu-HU       1.00      0.98      0.99      2033\n",
      "       is-IS       1.00      0.99      0.99      2033\n",
      "       it-IT       0.98      0.99      0.99      2033\n",
      "       jv-ID       0.99      0.98      0.99      2033\n",
      "       lv-LV       1.00      0.99      0.99      2033\n",
      "       ms-MY       0.99      0.99      0.99      2033\n",
      "       nb-NO       0.96      0.94      0.95      2033\n",
      "       nl-NL       0.98      0.97      0.98      2033\n",
      "       pl-PL       0.99      0.98      0.98      2033\n",
      "       pt-PT       0.98      0.98      0.98      2033\n",
      "       ro-RO       1.00      0.99      0.99      2033\n",
      "       ru-RU       1.00      0.99      1.00      2033\n",
      "       sl-SL       1.00      0.99      0.99      2033\n",
      "       sq-AL       1.00      0.99      0.99      2033\n",
      "       sv-SE       0.97      0.98      0.97      2033\n",
      "       sw-KE       1.00      0.99      1.00      2033\n",
      "       tl-PH       0.99      0.99      0.99      2033\n",
      "       tr-TR       1.00      0.99      0.99      2033\n",
      "       vi-VN       1.00      1.00      1.00      2033\n",
      "\n",
      "    accuracy                           0.98     54891\n",
      "   macro avg       0.98      0.98      0.98     54891\n",
      "weighted avg       0.98      0.98      0.98     54891\n",
      "\n",
      "Validation Accuracy: 0.9838589204058953\n"
     ]
    }
   ],
   "source": [
    "val_predictions = pipeline.predict(df1_val['utt'])\n",
    "print(\"Validation Data Performance:\")\n",
    "print(classification_report(df1_val['locale'], val_predictions))\n",
    "print(\"Validation Accuracy:\", accuracy_score(df1_val['locale'], val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tModel's perfomance metrics for Test Partition\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       af-ZA       0.89      0.98      0.94      2974\n",
      "       cy-GB       1.00      0.99      1.00      2974\n",
      "       da-DK       0.94      0.95      0.95      2974\n",
      "       de-DE       0.99      0.99      0.99      2974\n",
      "       en-US       0.94      0.99      0.97      2974\n",
      "       es-ES       0.98      0.98      0.98      2974\n",
      "       fi-FI       0.99      0.98      0.99      2974\n",
      "       fr-FR       0.99      0.99      0.99      2974\n",
      "       hu-HU       1.00      0.98      0.99      2974\n",
      "       is-IS       1.00      0.99      0.99      2974\n",
      "       it-IT       0.98      0.99      0.99      2974\n",
      "       jv-ID       0.99      0.98      0.99      2974\n",
      "       lv-LV       0.99      0.99      0.99      2974\n",
      "       ms-MY       0.99      0.99      0.99      2974\n",
      "       nb-NO       0.96      0.93      0.95      2974\n",
      "       nl-NL       0.99      0.97      0.98      2974\n",
      "       pl-PL       1.00      0.98      0.99      2974\n",
      "       pt-PT       0.98      0.98      0.98      2974\n",
      "       ro-RO       1.00      0.99      0.99      2974\n",
      "       ru-RU       1.00      0.99      1.00      2974\n",
      "       sl-SL       1.00      0.99      0.99      2974\n",
      "       sq-AL       1.00      0.99      0.99      2974\n",
      "       sv-SE       0.99      0.97      0.98      2974\n",
      "       sw-KE       1.00      0.99      1.00      2974\n",
      "       tl-PH       0.99      0.99      0.99      2974\n",
      "       tr-TR       0.99      0.99      0.99      2974\n",
      "       vi-VN       1.00      1.00      1.00      2974\n",
      "\n",
      "    accuracy                           0.98     80298\n",
      "   macro avg       0.98      0.98      0.98     80298\n",
      "weighted avg       0.98      0.98      0.98     80298\n",
      "\n",
      "Testing Accuracy: 0.9833868838576303\n"
     ]
    }
   ],
   "source": [
    "test_predictions = pipeline.predict(df1_test['utt'])\n",
    "print(\"Testing Data Performance:\")\n",
    "print(classification_report(df1_test['locale'], test_predictions))\n",
    "print(\"Testing Accuracy:\", accuracy_score(df1_test['locale'], test_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tNow, building a MultinomialNB model with accent removal from the data. For the \"unicodedata\" library is used. \n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCENT REMOVAL \n",
    "\n",
    "df2 = df_filtered\n",
    "# Function to deaccent characters\n",
    "def deaccent(text):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "# Create a directory to store the files\n",
    "\n",
    "# Iterate through the dataset and save sentences to respective files\n",
    "for locale in locales:\n",
    "    for partition in ['train', 'validation', 'test']:\n",
    "           for item in df2[partition]:\n",
    "                  if item['locale'] == locale:\n",
    "                          sentence = item['utt']\n",
    "                          sentence = deaccent(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_train = df2['train']\n",
    "df2_val = df2['validation']\n",
    "df2_test = df2['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tBuilding Multinomial Naive Bayes Model - with accents\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectoriser&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectoriser&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectoriser', CountVectorizer()),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectoriser', CountVectorizer()), \n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline.fit(df2_train['utt'], df2_train['locale'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tModel's perfomance metrics for Train Partition\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       af-ZA       0.98      0.98      0.98     11514\n",
      "       cy-GB       1.00      1.00      1.00     11514\n",
      "       da-DK       0.97      0.97      0.97     11514\n",
      "       de-DE       1.00      0.99      0.99     11514\n",
      "       en-US       0.96      0.99      0.98     11514\n",
      "       es-ES       0.99      0.99      0.99     11514\n",
      "       fi-FI       1.00      0.99      0.99     11514\n",
      "       fr-FR       0.99      0.99      0.99     11514\n",
      "       hu-HU       1.00      0.99      1.00     11514\n",
      "       is-IS       1.00      1.00      1.00     11514\n",
      "       it-IT       0.99      0.99      0.99     11514\n",
      "       jv-ID       0.99      0.99      0.99     11514\n",
      "       lv-LV       1.00      1.00      1.00     11514\n",
      "       ms-MY       0.99      0.99      0.99     11514\n",
      "       nb-NO       0.97      0.96      0.97     11514\n",
      "       nl-NL       0.99      0.98      0.98     11514\n",
      "       pl-PL       0.99      0.99      0.99     11514\n",
      "       pt-PT       0.99      0.99      0.99     11514\n",
      "       ro-RO       1.00      0.99      0.99     11514\n",
      "       ru-RU       1.00      1.00      1.00     11514\n",
      "       sl-SL       1.00      0.99      1.00     11514\n",
      "       sq-AL       1.00      0.99      1.00     11514\n",
      "       sv-SE       0.99      0.99      0.99     11514\n",
      "       sw-KE       1.00      1.00      1.00     11514\n",
      "       tl-PH       1.00      1.00      1.00     11514\n",
      "       tr-TR       1.00      0.99      1.00     11514\n",
      "       vi-VN       1.00      1.00      1.00     11514\n",
      "\n",
      "    accuracy                           0.99    310878\n",
      "   macro avg       0.99      0.99      0.99    310878\n",
      "weighted avg       0.99      0.99      0.99    310878\n",
      "\n",
      "Training Accuracy: 0.9909160506693945\n"
     ]
    }
   ],
   "source": [
    "train_predictions = pipeline.predict(df2_train['utt'])\n",
    "print(\"Training Data Performance:\")\n",
    "print(classification_report(df2_train['locale'], train_predictions))\n",
    "print(\"Training Accuracy:\", accuracy_score(df2_train['locale'], train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tModel's perfomance metrics for Validation Partition\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       af-ZA       0.91      0.98      0.94      2033\n",
      "       cy-GB       1.00      0.99      0.99      2033\n",
      "       da-DK       0.94      0.96      0.95      2033\n",
      "       de-DE       1.00      0.98      0.99      2033\n",
      "       en-US       0.96      0.99      0.98      2033\n",
      "       es-ES       0.98      0.98      0.98      2033\n",
      "       fi-FI       1.00      0.98      0.99      2033\n",
      "       fr-FR       0.99      0.99      0.99      2033\n",
      "       hu-HU       1.00      0.98      0.99      2033\n",
      "       is-IS       1.00      0.99      0.99      2033\n",
      "       it-IT       0.98      0.99      0.99      2033\n",
      "       jv-ID       0.99      0.98      0.99      2033\n",
      "       lv-LV       1.00      0.99      0.99      2033\n",
      "       ms-MY       0.99      0.99      0.99      2033\n",
      "       nb-NO       0.96      0.94      0.95      2033\n",
      "       nl-NL       0.98      0.97      0.98      2033\n",
      "       pl-PL       0.99      0.98      0.98      2033\n",
      "       pt-PT       0.98      0.98      0.98      2033\n",
      "       ro-RO       1.00      0.99      0.99      2033\n",
      "       ru-RU       1.00      0.99      1.00      2033\n",
      "       sl-SL       1.00      0.99      0.99      2033\n",
      "       sq-AL       1.00      0.99      0.99      2033\n",
      "       sv-SE       0.97      0.98      0.97      2033\n",
      "       sw-KE       1.00      0.99      1.00      2033\n",
      "       tl-PH       0.99      0.99      0.99      2033\n",
      "       tr-TR       1.00      0.99      0.99      2033\n",
      "       vi-VN       1.00      1.00      1.00      2033\n",
      "\n",
      "    accuracy                           0.98     54891\n",
      "   macro avg       0.98      0.98      0.98     54891\n",
      "weighted avg       0.98      0.98      0.98     54891\n",
      "\n",
      "Validation Accuracy: 0.9838589204058953\n"
     ]
    }
   ],
   "source": [
    "val_predictions = pipeline.predict(df2_val['utt'])\n",
    "print(\"Validation Data Performance:\")\n",
    "print(classification_report(df2_val['locale'], val_predictions))\n",
    "print(\"Validation Accuracy:\", accuracy_score(df2_val['locale'], val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tModel's perfomance metrics for Test Partition\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       af-ZA       0.89      0.98      0.94      2974\n",
      "       cy-GB       1.00      0.99      1.00      2974\n",
      "       da-DK       0.94      0.95      0.95      2974\n",
      "       de-DE       0.99      0.99      0.99      2974\n",
      "       en-US       0.94      0.99      0.97      2974\n",
      "       es-ES       0.98      0.98      0.98      2974\n",
      "       fi-FI       0.99      0.98      0.99      2974\n",
      "       fr-FR       0.99      0.99      0.99      2974\n",
      "       hu-HU       1.00      0.98      0.99      2974\n",
      "       is-IS       1.00      0.99      0.99      2974\n",
      "       it-IT       0.98      0.99      0.99      2974\n",
      "       jv-ID       0.99      0.98      0.99      2974\n",
      "       lv-LV       0.99      0.99      0.99      2974\n",
      "       ms-MY       0.99      0.99      0.99      2974\n",
      "       nb-NO       0.96      0.93      0.95      2974\n",
      "       nl-NL       0.99      0.97      0.98      2974\n",
      "       pl-PL       1.00      0.98      0.99      2974\n",
      "       pt-PT       0.98      0.98      0.98      2974\n",
      "       ro-RO       1.00      0.99      0.99      2974\n",
      "       ru-RU       1.00      0.99      1.00      2974\n",
      "       sl-SL       1.00      0.99      0.99      2974\n",
      "       sq-AL       1.00      0.99      0.99      2974\n",
      "       sv-SE       0.99      0.97      0.98      2974\n",
      "       sw-KE       1.00      0.99      1.00      2974\n",
      "       tl-PH       0.99      0.99      0.99      2974\n",
      "       tr-TR       0.99      0.99      0.99      2974\n",
      "       vi-VN       1.00      1.00      1.00      2974\n",
      "\n",
      "    accuracy                           0.98     80298\n",
      "   macro avg       0.98      0.98      0.98     80298\n",
      "weighted avg       0.98      0.98      0.98     80298\n",
      "\n",
      "Testing Accuracy: 0.9833868838576303\n"
     ]
    }
   ],
   "source": [
    "test_predictions = pipeline.predict(df2_test['utt'])\n",
    "print(\"Testing Data Performance:\")\n",
    "print(classification_report(df2_test['locale'], test_predictions))\n",
    "print(\"Testing Accuracy:\", accuracy_score(df2_test['locale'], test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tFrom the above results, We can see that keeping accents in the data is useful for language classification. Accuracy for model without removing accents is 99% and accuracy for model without accents is 98%. Note the fact that, the Precision for model with accents is higher than the precision for the model wihtout accents. \n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TASK 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tCollapsing the choosen 27 languages into a 4 label dataset, where the labels are the continent they are spoken in. Building a Regularised Discriminent Analyser (RDA) over the above modified data with Linear Discriminent Analyser (LDA) and Quadratic Discriminent Analyser (QDA) with a parameter which balances the prfedictions of both. \n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "continent_groups = {\n",
    "    'af-ZA': 'Africa', 'sw-KE': 'Africa',\n",
    "    'da-DK': 'Europe', 'de-DE': 'Europe', 'es-ES': 'Europe', 'fr-FR': 'Europe', 'fi-FI': 'Europe',\n",
    "    'hu-HU': 'Europe', 'is-IS': 'Europe', 'it-IT': 'Europe', 'lv-LV': 'Europe', 'nb-NO': 'Europe',\n",
    "    'nl-NL': 'Europe', 'pl-PL': 'Europe', 'pt-PT': 'Europe', 'ro-RO': 'Europe', 'ru-RU': 'Europe',\n",
    "    'sl-SL': 'Europe', 'sv-SE': 'Europe', 'sq-AL': 'Europe', 'cy-GB': 'Europe',\n",
    "    'jv-ID': 'Asia', 'ms-MY': 'Asia', 'tl-PH': 'Asia', 'tr-TR': 'Asia', 'vi-VN': 'Asia',\n",
    "    'en-US': 'North America'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tCreating a extral column in the dataset and adding the continent value to the corresponding language and then passing the new column as the label for the RDA Model \n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_continent(row): \n",
    "    locale = row['locale']\n",
    "    return continent_groups.get(locale, 'NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tUsing 'lambda' functions in python to apply the above function to add the continent names. \n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df_filtered['train'].map(lambda row: {'continent': assign_continent(row)})\n",
    "val_data = df_filtered['validation'].map(lambda row: {'continent': assign_continent(row)})\n",
    "test_data = df_filtered['test'].map(lambda row: {'continent': assign_continent(row)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tClass for Regularised Discriminent Analysis \n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin # to get two classifiers inside a single class # type: ignore \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis # type: ignore \n",
    "from sklearn.metrics import accuracy_score # type: ignore \n",
    "\n",
    "class RegularizedDiscriminantAnalysis(BaseEstimator, ClassifierMixin):\n",
    "    __slots__ = '_lambda'\n",
    "    def __init__(self, _lambda=0.5):\n",
    "        self._lambda = _lambda\n",
    "        self.lda = LinearDiscriminantAnalysis()\n",
    "        self.qda = QuadraticDiscriminantAnalysis()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.lda.fit(X, y)\n",
    "        self.qda.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        lda_pred = self.lda.predict_proba(X)\n",
    "        qda_pred = self.qda.predict_proba(X)\n",
    "        combined_pred = ((1 - self._lambda) * lda_pred) + (self._lambda * qda_pred)\n",
    "        return np.argmax(combined_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tUsing min frequency prunning (min_df = 10) and limiting the features to 250, the model is build and tunned for hyper parameter lambda\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = CountVectorizer(max_features=400, min_df=10).fit_transform(train_data['utt'])\n",
    "y_train = LabelEncoder().fit_transform(train_data['continent'])\n",
    "\n",
    "X_test_vec = CountVectorizer(max_features=400, min_df=10).fit_transform(test_data['utt'])\n",
    "y_test = LabelEncoder().fit_transform(test_data['continent'])\n",
    "\n",
    "X_val_vec = CountVectorizer(max_features=400, min_df=10).fit_transform(val_data['utt'])\n",
    "y_val = LabelEncoder().fit_transform(val_data['continent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RegularizedDiscriminantAnalysis(_lambda=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RegularizedDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>RegularizedDiscriminantAnalysis(_lambda=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RegularizedDiscriminantAnalysis(_lambda=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the RDA model\n",
    "rda = RegularizedDiscriminantAnalysis(_lambda=0)\n",
    "rda.fit(X_train_vec.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6566913248150639\n"
     ]
    }
   ],
   "source": [
    "y_test = LabelEncoder().fit_transform(y_test)\n",
    "# Predict and evaluate the model\n",
    "y_pred = rda.predict(X_test_vec.toarray())\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration0 Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration1 Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration2 Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration3 Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration4 Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration5 Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration6 Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration7 Done\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "parameter_grid =  [0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1]\n",
    "best_accuracy = float('-inf')\n",
    "best_parameter = 0\n",
    "\n",
    "for i in range(0, len(parameter_grid)): \n",
    "    model = RegularizedDiscriminantAnalysis(_lambda = parameter_grid[i]).fit(X_train_vec.toarray(), y_train)\n",
    "    y_pred = model.predict(X_val_vec.toarray())\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    if(accuracy > best_accuracy): \n",
    "        best_parameter = parameter_grid[i]\n",
    "        best_accuracy = accuracy\n",
    "    print(f'Iteration{i} Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.733599315006103"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'> \n",
    "\tAfter hyperparameter tuning, the best parameter is lambda = 0. With the best parameter, the accuracy is 73.5% with max_df = 10 and max_features = 400 in counter vectoriser. \n",
    "<p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
